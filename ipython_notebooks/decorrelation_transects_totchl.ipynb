{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import acf, ccf\n",
    "from statsmodels.tsa.tsatools import detrend\n",
    "\n",
    "import gsw as sw\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from netCDF4 import Dataset as NetCDFFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indices(a, func):\n",
    "    return [i for (i, val) in enumerate(a) if func(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import data directly from myria\n",
    "\n",
    "fileURL = 'https://rest.myria.cs.washington.edu:1776/dataset/user-armbrustlab/program-seaflow/relation-tot_chl_byfile/data?format=csv'\n",
    "result = pd.read_csv(fileURL)\n",
    "# pick out the subset of variables to use for clustering/PCA\n",
    "print result.columns\n",
    "\n",
    "fileURL = 'https://rest.myria.cs.washington.edu:1776/dataset/user-armbrustlab/program-seaflow/relation-all_sds_v2/data?format=csv'\n",
    "sds = pd.read_csv(fileURL)\n",
    "sds.rename(columns={'file': 'File_Id', 'day': 'Day'}, inplace=True)\n",
    "print sds.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join sds dataframe to opp file averages\n",
    "\n",
    "print sds.shape\n",
    "#print type(sds), type(cIdx[9])\n",
    "#new_table = pd.merge(sds, result, how=\"inner\")\n",
    "new_table = pd.merge(sds, result, how=\"inner\")\n",
    "\n",
    "\n",
    "#X = new_table[['fsc_avg','chl_avg','pe_avg','fsc_var','chl_var','pe_var']].values  \n",
    "X = new_table[['tot_chl']].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# identify continuous transects\n",
    "# start by just picking out cruises that we know fit the bill\n",
    "\n",
    "# look at how the clusters relate to physical properties of the water column...\n",
    "\n",
    "cr = 'Thompson_1'\n",
    "crsub = new_table[(new_table['Cruise']==cr)].sort(['Day','File_Id'],ascending=[1,1])\n",
    "crsub['density'] = sw.rho(crsub['S'].values,crsub['T'].values,0)\n",
    "\n",
    "cxx = (crsub['LON']).values # longitude\n",
    "cyy = (crsub['LAT']).values # latitude\n",
    "\n",
    "# convert all longitude to longitude east\n",
    "cxx[cxx<0]= 360+cxx[cxx<0];\n",
    "cxbew = cxx\n",
    "cxbew[cxbew>180] = cxbew[cxbew>180]-360\n",
    "\n",
    "# calculate distance between points\n",
    "cdistance = sw.distance(cxbew,cyy, 0)[0]\n",
    "ctrack = np.cumsum(cdistance)\n",
    "ctrack = np.insert(ctrack, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the cruise track\n",
    "\n",
    "fig1 = plt.figure(1, figsize=(15,9))\n",
    "\n",
    "m = Basemap(width=12000000,height=9000000,projection='lcc',\n",
    "            resolution='c',lat_1=15.,lat_2=60,lat_0=45,lon_0=-180.)\n",
    "m.drawcoastlines()\n",
    "m.drawmapboundary(fill_color='white')\n",
    "m.fillcontinents(color='grey',lake_color='white')\n",
    "#plt.axes([0.025, 0.025, 0.95, 0.95])\n",
    "xm, ym = m(cxbew,cyy)\n",
    "m.scatter(xm, ym, s=75, c=crsub['tot_chl'], alpha=.5,lw=0)\n",
    "\n",
    "m.drawparallels(np.arange(10,90,20),labels=[1,1,0,1])\n",
    "m.drawmeridians(np.arange(-180,180,30),labels=[1,1,0,1])\n",
    "\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print cyy.min(); cyy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"continuous\" tracks of data are found between 63:950 952:1015 1017:1371\n",
    "# now turn these into 3 separate datasets, track1, track2 and track3\n",
    "# check the lemgth of these tracks\n",
    "\n",
    "t1 = ctrack[950]-ctrack[63] #1174km long\n",
    "t2 = ctrack[1015]-ctrack[952] #108km long, this track is short and a bit dodgy\n",
    "t3 = ctrack[1371]-ctrack[1017] #458km long\n",
    "\n",
    "# split the subset into tracks\n",
    "t1sub = crsub.iloc[63:950]\n",
    "t2sub = crsub.iloc[952:1015]\n",
    "t3sub = crsub.iloc[1017:1371]\n",
    "\n",
    "# split the tracks\n",
    "t1track = ctrack[63:950]-ctrack[63]\n",
    "t2track = ctrack[952:1015]-ctrack[952]\n",
    "t3track = ctrack[1017:1371]-ctrack[1017]\n",
    "\n",
    "\n",
    "# check the effective resolution for the tracks\n",
    "print cdistance[63:950].mean()/1000, cdistance[63:950].std()/1000\n",
    "print cdistance[952:1015].mean()/1000, cdistance[952:1015].std()/1000\n",
    "print cdistance[1017:1371].mean()/1000, cdistance[1017:1371].std()/1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(cdistance[63:950]/1000,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interpolate the tracks onto a regular n km grid\n",
    "# set the interpolation scale, n\n",
    "n = 2\n",
    "\n",
    "t1x = np.arange(0,t1+1000, n*1000)\n",
    "t3x = np.arange(0,t3+1000, n*1000)\n",
    "t1int = np.interp(t1x,t1track,t1sub['tot_chl'].values)\n",
    "t3int = np.interp(t3x,t3track,t3sub['tot_chl'].values)\n",
    "\n",
    "t1intT = np.interp(t1x,t1track,t1sub['T'].values)\n",
    "t3intT = np.interp(t3x,t3track,t3sub['T'].values)\n",
    "\n",
    "plt.plot(t1x/1000,t1int,t1track/1000,t1sub['tot_chl'].values,'x')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(t3x/1000,t3int,t3track/1000,t3sub['tot_chl'].values,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab subsets of each track, detrend them and do autocorrelation to get decorrelation length scale\n",
    "# track 1\n",
    "\n",
    "#plt.plot(t1x[0:100]/1000,detrend(t1int[0:100], order=1))\n",
    "#plt.show()\n",
    "\n",
    "#plt.plot(t3x[0:100]/1000,detrend(t3int[0:100], order=1))\n",
    "#plt.show()\n",
    "plt.hold(True)\n",
    "plt.plot(acf(detrend(t1int[0:200], order=1), unbiased =True, nlags = 200),'b')\n",
    "plt.plot(acf(detrend(t1intT[0:200], order=1), unbiased =True, nlags = 200),'r')\n",
    "plt.axhline()\n",
    "plt.show()\n",
    "\n",
    "plt.hold(True)\n",
    "plt.plot(acf(detrend(t3int[0:200], order=1), unbiased =True, nlags = 200),'b')\n",
    "plt.plot(acf(detrend(t3intT[0:200], order=1), unbiased =True, nlags = 200),'r')\n",
    "plt.axhline()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab subsets of each track, detrend them and do autocorrelation to get decorrelation length scale\n",
    "# track 1\n",
    "\n",
    "#plt.plot(t1x[0:100]/1000,detrend(t1int[0:100], order=1))\n",
    "#plt.show()\n",
    "\n",
    "#plt.plot(t3x[0:100]/1000,detrend(t3int[0:100], order=1))\n",
    "#plt.show()\n",
    "plt.hold(True)\n",
    "plt.plot(acf(detrend(t1int[100:300], order=1), unbiased =True, nlags = 200),'b')\n",
    "plt.plot(acf(detrend(t1intT[100:300], order=1), unbiased =True, nlags = 200),'r')\n",
    "plt.axhline()\n",
    "plt.show()\n",
    "\n",
    "plt.hold(True)\n",
    "plt.plot(acf(detrend(t3int[100:300], order=1), unbiased =True, nlags = 200),'b')\n",
    "plt.plot(acf(detrend(t3intT[100:300], order=1), unbiased =True, nlags = 200),'r')\n",
    "plt.axhline()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now try to sequentially detrend and calculate acf for a moving window of data\n",
    "# this should be done over a window of at least 200km (or close to the eddy variability wavelength)\n",
    "\n",
    "# pick the track to analyse\n",
    "data_in = t1int\n",
    "data_inT = t1intT\n",
    "x_in = t1x\n",
    "\n",
    "ll = 200 # length of segment\n",
    "lf = np.int(np.floor((np.max(x_in)/1000)-ll)) # last possible start point for a segment\n",
    "print lf\n",
    "\n",
    "decorr_lT = np.zeros(lf/n)\n",
    "decorr_l = np.zeros(lf/n)\n",
    "\n",
    "for t in range(lf/n):\n",
    "    data = data_in[t:t+(ll/n)]\n",
    "    tr_acf = acf(detrend(data,order=1),unbiased =True, nlags = ll)\n",
    "    zero_crossings = np.where(np.diff(np.sign(tr_acf)))[0]\n",
    "    dc_ind = zero_crossings[0]\n",
    "    decorr_l[t] = (dc_ind + ((0-tr_acf[dc_ind])/(tr_acf[dc_ind+1]-tr_acf[dc_ind]))*n)\n",
    "    \n",
    "    dataT = data_inT[t:t+(ll/n)]\n",
    "    trT_acf = acf(detrend(dataT,order=1),unbiased =True, nlags = ll)\n",
    "    zero_crossingsT = np.where(np.diff(np.sign(trT_acf)))[0]\n",
    "    dc_indT = zero_crossingsT[0]\n",
    "    decorr_lT[t] = (dc_indT + ((0-trT_acf[dc_indT])/(trT_acf[dc_indT+1]-trT_acf[dc_indT])))*n\n",
    "    \n",
    "    \n",
    "plt.hold(True)\n",
    "plt.plot(decorr_l,'b')\n",
    "plt.plot(decorr_lT,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now try to sequentially detrend and calculate acf for a moving window of data\n",
    "# this should be done over a window of at least 200km (or close to the eddy variability wavelength)\n",
    "\n",
    "# pick the track to analyse\n",
    "data_in = t3int\n",
    "data_inT = t3intT\n",
    "x_in = t3x\n",
    "\n",
    "ll = 200 # length of segment\n",
    "lf = np.int(np.floor((np.max(x_in)/1000)-ll)) # last possible start point for a segment\n",
    "print lf\n",
    "\n",
    "decorr_lT = np.zeros(lf/n)\n",
    "decorr_l = np.zeros(lf/n)\n",
    "\n",
    "for t in range(lf/n):\n",
    "    data = data_in[t:t+200]\n",
    "    tr_acf = acf(detrend(data,order=1),unbiased =True, nlags = ll)\n",
    "    zero_crossings = np.where(np.diff(np.sign(tr_acf)))[0]\n",
    "    dc_ind = zero_crossings[0]\n",
    "    decorr_l[t] = (dc_ind + ((0-tr_acf[dc_ind])/(tr_acf[dc_ind+1]-tr_acf[dc_ind])))*n\n",
    "    \n",
    "    dataT = data_inT[t:t+200]\n",
    "    trT_acf = acf(detrend(dataT,order=1),unbiased =True, nlags = ll)\n",
    "    zero_crossingsT = np.where(np.diff(np.sign(trT_acf)))[0]\n",
    "    dc_indT = zero_crossingsT[0]\n",
    "    decorr_lT[t] = (dc_indT + ((0-trT_acf[dc_indT])/(trT_acf[dc_indT+1]-trT_acf[dc_indT])))*n\n",
    "    \n",
    "    \n",
    "plt.hold(True)\n",
    "plt.plot(decorr_l,'b')\n",
    "plt.plot(decorr_lT,'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
